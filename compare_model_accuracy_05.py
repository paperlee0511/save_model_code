import os
import yaml
from pathlib import Path
from ultralytics import YOLO
import pandas as pd
"""
ëª¨ë¸ ì •í™•ë„ ë¹„êµ
"""

class AccuracyComparator:
    """ëª¨ë¸ ì •í™•ë„ ë¹„êµ ë„êµ¬"""

    def __init__(self, data_yaml_path="data.yaml"):
        """
        Args:
            data_yaml_path (str): ë°ì´í„° ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.data_yaml_path = data_yaml_path
        self.results = {}

        # ë°ì´í„° ì„¤ì • í™•ì¸
        if not Path(data_yaml_path).exists():
            print(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_yaml_path}")
            return

        print("ğŸ“Š ì •í™•ë„ ë¹„êµê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def evaluate_pytorch_model(self, model_path):
        """PyTorch ëª¨ë¸ ì •í™•ë„ í‰ê°€"""
        print(f"\nğŸ” PyTorch ëª¨ë¸ í‰ê°€ ì¤‘: {model_path}")

        try:
            model = YOLO(model_path)
            metrics = model.val(data=self.data_yaml_path, verbose=False)

            result = {
                'model_type': 'PyTorch',
                'model_path': model_path,
                'map50': float(metrics.box.map50),
                'map50_95': float(metrics.box.map),
                'precision': float(metrics.box.mp),
                'recall': float(metrics.box.mr),
                'f1_score': 2 * (float(metrics.box.mp) * float(metrics.box.mr)) / (
                            float(metrics.box.mp) + float(metrics.box.mr)) if (float(metrics.box.mp) + float(
                    metrics.box.mr)) > 0 else 0
            }

            self.results['pytorch'] = result
            print("âœ… PyTorch ëª¨ë¸ í‰ê°€ ì™„ë£Œ")
            return result

        except Exception as e:
            print(f"âŒ PyTorch ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")
            return None

    def evaluate_openvino_model(self, model_path, model_type="fp16"):
        """OpenVINO ëª¨ë¸ ì •í™•ë„ í‰ê°€ (YOLOë¡œ ë¡œë“œ)"""
        print(f"\nğŸ” OpenVINO {model_type.upper()} ëª¨ë¸ í‰ê°€ ì¤‘: {model_path}")

        try:
            # OpenVINO ëª¨ë¸ì„ YOLOë¡œ ë¡œë“œ (ê°„ì ‘ì  ë°©ë²•)
            model = YOLO(model_path)
            metrics = model.val(data=self.data_yaml_path, verbose=False)

            result = {
                'model_type': f'OpenVINO {model_type.upper()}',
                'model_path': model_path,
                'map50': float(metrics.box.map50),
                'map50_95': float(metrics.box.map),
                'precision': float(metrics.box.mp),
                'recall': float(metrics.box.mr),
                'f1_score': 2 * (float(metrics.box.mp) * float(metrics.box.mr)) / (
                            float(metrics.box.mp) + float(metrics.box.mr)) if (float(metrics.box.mp) + float(
                    metrics.box.mr)) > 0 else 0
            }

            self.results[model_type] = result
            print(f"âœ… OpenVINO {model_type.upper()} ëª¨ë¸ í‰ê°€ ì™„ë£Œ")
            return result

        except Exception as e:
            print(f"âŒ OpenVINO {model_type.upper()} ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")
            return None

    def compare_all_models(self, pytorch_path, fp16_path=None, int8_path=None):
        """ëª¨ë“  ëª¨ë¸ ì •í™•ë„ ë¹„êµ"""
        print("\nğŸ¯ ì „ì²´ ëª¨ë¸ ì •í™•ë„ ë¹„êµ ì‹œì‘!")
        print("=" * 60)

        # PyTorch ëª¨ë¸ í‰ê°€
        if Path(pytorch_path).exists():
            self.evaluate_pytorch_model(pytorch_path)
        else:
            print(f"âŒ PyTorch ëª¨ë¸ ì—†ìŒ: {pytorch_path}")

        # FP16 ëª¨ë¸ í‰ê°€
        if fp16_path and Path(fp16_path).exists():
            self.evaluate_openvino_model(fp16_path, "fp16")
        else:
            print(f"âš ï¸ FP16 ëª¨ë¸ ê±´ë„ˆëœ€")

        # INT8 ëª¨ë¸ í‰ê°€
        if int8_path and Path(int8_path).exists():
            self.evaluate_openvino_model(int8_path, "int8")
        else:
            print(f"âš ï¸ INT8 ëª¨ë¸ ê±´ë„ˆëœ€")

        # ê²°ê³¼ ì¶œë ¥
        self.show_accuracy_results()

        return self.results

    def show_accuracy_results(self):
        """ì •í™•ë„ ê²°ê³¼ ì¶œë ¥"""
        if not self.results:
            print("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ“Š ì •í™•ë„ ë¹„êµ ê²°ê³¼")
        print("=" * 80)

        # í‘œ í˜•íƒœë¡œ ê²°ê³¼ ì •ë¦¬
        df_data = []
        for key, result in self.results.items():
            df_data.append({
                'ëª¨ë¸': result['model_type'],
                'mAP@0.5': f"{result['map50']:.4f}",
                'mAP@0.5:0.95': f"{result['map50_95']:.4f}",
                'Precision': f"{result['precision']:.4f}",
                'Recall': f"{result['recall']:.4f}",
                'F1-Score': f"{result['f1_score']:.4f}"
            })

        df = pd.DataFrame(df_data)
        print(df.to_string(index=False))

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
        if len(self.results) > 1:
            best_map50 = max(self.results.values(), key=lambda x: x['map50'])
            best_map50_95 = max(self.results.values(), key=lambda x: x['map50_95'])

            print(f"\nğŸ† ìµœê³  mAP@0.5: {best_map50['model_type']} ({best_map50['map50']:.4f})")
            print(f"ğŸ† ìµœê³  mAP@0.5:0.95: {best_map50_95['model_type']} ({best_map50_95['map50_95']:.4f})")

        # ì •í™•ë„ ì†ì‹¤ ë¶„ì„
        self.analyze_accuracy_loss()

    def analyze_accuracy_loss(self):
        """ì •í™•ë„ ì†ì‹¤ ë¶„ì„"""
        if 'pytorch' not in self.results:
            print("âš ï¸ PyTorch ê¸°ì¤€ ëª¨ë¸ì´ ì—†ì–´ ì†ì‹¤ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"\nğŸ“‰ PyTorch ëŒ€ë¹„ ì •í™•ë„ ì†ì‹¤ ë¶„ì„:")
        pytorch_map50 = self.results['pytorch']['map50']
        pytorch_map50_95 = self.results['pytorch']['map50_95']

        for key, result in self.results.items():
            if key == 'pytorch':
                continue

            map50_loss = (pytorch_map50 - result['map50']) / pytorch_map50 * 100
            map50_95_loss = (pytorch_map50_95 - result['map50_95']) / pytorch_map50_95 * 100

            print(f"  {result['model_type']}:")
            print(f"    - mAP@0.5 ì†ì‹¤: {map50_loss:.2f}%")
            print(f"    - mAP@0.5:0.95 ì†ì‹¤: {map50_95_loss:.2f}%")

    def save_results(self, output_path="accuracy_comparison.csv"):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        if not self.results:
            print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        df_data = []
        for key, result in self.results.items():
            df_data.append(result)

        df = pd.DataFrame(df_data)
        df.to_csv(output_path, index=False)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì •í™•ë„ ë¹„êµê¸° ìƒì„±
    comparator = AccuracyComparator("data.yaml")

    # ëª¨ë“  ëª¨ë¸ ì •í™•ë„ ë¹„êµ
    results = comparator.compare_all_models(
        pytorch_path="snack_detection/yolov8s_custom/weights/best.pt",
        fp16_path="models/best_openvino_model/best.xml",
        int8_path="models/best_int8_openvino_model/best.xml"
    )

    # ê²°ê³¼ ì €ì¥
    comparator.save_results("accuracy_comparison.csv")

    print("\nğŸ‰ ì •í™•ë„ ë¹„êµ ì™„ë£Œ!")